{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analiza društvene mreže Reddit\n",
    "\n",
    "Univerzitet u Beogradu, Elektrotehnički fakultet, veb adresa [ovde](https://www.etf.bg.ac.rs).  \n",
    "Predmet: Analiza socijalnih mreža, veb adresa [ovde](https://rti.etf.bg.ac.rs/rti/ms1asm/).  \n",
    "Tekst projektnog zadatka se može naći na veb sajtu predmeta [ovde](https://rti.etf.bg.ac.rs/rti/ms1asm/projekti/2021-2022/ASM_PZ2_2122.pdf).  \n",
    "- Bogdan Bebić 2022/3051\n",
    "- Marta Avramović 2022/3166"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalacija i učitavanje korišćenih biblioteka\n",
    "Neophodne bilioteke se mogu instalirati korišćenjem Python package instalera `pip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format skupa podataka\n",
    "Podaci su preuzeti sa sajta predmeta i otpakovani u odgovarajuće direktorijume.\n",
    "Kako postoji više datoteka sa istim tipom podataka, učitavamo ih sve zajedno i spajamo u jedinstvenu strukturu podataka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_data_path = \"ASM_PZ2_podaci_2122/reddit2008\"\n",
    "submission_dataPath = f\"{reddit_data_path}/submissions_2008_asm/\"\n",
    "comments_dataPath = f\"{reddit_data_path}/comments_2008_asm_v1.1/comments_2008/\"\n",
    "\n",
    "\n",
    "def loadDataSet(folderPath):\n",
    "    allFileData = pd.DataFrame([])\n",
    "    for fileName in os.listdir(folderPath):\n",
    "        singleFileData = pd.read_csv(folderPath + fileName, low_memory=False)\n",
    "        allFileData = pd.concat([allFileData, singleFileData])\n",
    "\n",
    "    return allFileData\n",
    "\n",
    "\n",
    "def groupby_count(data_frame, groupby_list):\n",
    "    return data_frame.groupby(groupby_list).size().reset_index(name=\"counts\")\n",
    "\n",
    "\n",
    "def groupby_count_sorted(data_frame, groupby_list):\n",
    "    return groupby_count(data_frame, groupby_list).sort_values('counts', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtriranje skupa podataka\n",
    "Na društvenoj mreži Reddit je moguće obrisati nalog - u tom slučaju se mogu dobiti podaci koji sadrže `[deleted]` kao korisničko ime.\n",
    "Ovakvi podaci nepovoljno utiču na analizu jer su ti nalozi mogli pripadati proizvoljnom broju korisnika i stoga ih filtriramo i ne koristimo u daljoj analizi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissionData = loadDataSet(submission_dataPath)\n",
    "commentsData = loadDataSet(comments_dataPath)\n",
    "\n",
    "# It is possible to have \"[deleted]\" as author name\n",
    "submissionFilter = submissionData[\"author\"] != \"[deleted]\"\n",
    "commentsFilter = commentsData[\"author\"] != \"[deleted]\"\n",
    "\n",
    "filteredSubmissions = submissionData[submissionFilter]\n",
    "filteredComments = commentsData[commentsFilter]\n",
    "\n",
    "allData = pd.concat([filteredSubmissions, filteredComments])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistička obrada podataka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different subreddits: 5032\n",
      "Comments per subreddit:\n",
      "     subreddit_id   counts\n",
      "2689         t5_6  1884629\n",
      "Authors per subreddit:\n",
      "     subreddit_id  counts\n",
      "4354         t5_6  163779\n",
      "AVG number users per subreddit:\n",
      "128.78398251192368\n",
      "Max submissions per author:\n",
      "      author  counts\n",
      "84823    gst   18870\n",
      "Max comments per author:\n",
      "                author  counts\n",
      "12603  NoMoreNicksLeft   13480\n",
      "Subreddits per author:\n",
      "         author  counts\n",
      "26173  MrKlaatu     181\n"
     ]
    }
   ],
   "source": [
    "allSubredditIds = np.union1d(submissionData['subreddit_id'], commentsData['subreddit_id'])\n",
    "print(f\"Number of different subreddits: {len(allSubredditIds)}\")\n",
    "\n",
    "commentsPerSubreddit = groupby_count_sorted(commentsData, [\"subreddit_id\"])\n",
    "print(f\"Comments per subreddit:\\n{commentsPerSubreddit[:1]}\")\n",
    "\n",
    "# subreddit - author - count interactions\n",
    "interactionsPerAuthorPerSubreddit = groupby_count(allData, [\"subreddit_id\", \"author\"])\n",
    "# subreddit - count authors\n",
    "authorsPerSubreddit = groupby_count_sorted(interactionsPerAuthorPerSubreddit, [\"subreddit_id\"])\n",
    "print(f\"Authors per subreddit:\\n{authorsPerSubreddit[:1]}\")\n",
    "\n",
    "print(f\"AVG number users per subreddit:\\n{authorsPerSubreddit['counts'].sum() / len(allSubredditIds)}\")\n",
    "\n",
    "submissionsPerAuthor = groupby_count_sorted(filteredSubmissions, ['author'])\n",
    "commentsPerAuthor = groupby_count_sorted(filteredComments, ['author'])\n",
    "print(f\"Max submissions per author:\\n{submissionsPerAuthor[:1]}\")\n",
    "print(f\"Max comments per author:\\n{commentsPerAuthor[:1]}\")\n",
    "\n",
    "# author - subreddit - count interactions\n",
    "interactionsPerSubredditPerAuthor = groupby_count(allData, ['author', 'subreddit_id'])\n",
    "# author - count subreddits\n",
    "subredditsPerAuthor = groupby_count_sorted(interactionsPerSubredditPerAuthor, ['author'])\n",
    "print(f\"Subreddits per author:\\n{subredditsPerAuthor[:1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paersonCalculation = submissionsPerAuthor.copy().merge(commentsPerAuthor.copy(), on=\"author\", how=\"inner\", suffixes=[\"_submissions\", \"_comments\"])\n",
    "paersonCalculation.plot.scatter(y=\"counts_submissions\", x=\"counts_comments\")\n",
    "print(f\"Pearson correlation matrix:\\n{paersonCalculation.corr(method='pearson')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterNonOver18 = submissionData[\"over_18\"] == False\n",
    "filteredSubmissionsNonOver18 = submissionData[filterNonOver18]\n",
    "extractedCommentsData = pd.DataFrame(commentsData[\"link_id\"].map(lambda element: element.split(\"_\")[1]))\n",
    "commentsDataSubmissionId = groupby_count_sorted(extractedCommentsData, [\"link_id\"]).rename(columns={\"link_id\": \"id\"})\n",
    "filteredSubmissionsNonOver18JoinedComments = filteredSubmissionsNonOver18.merge(commentsDataSubmissionId, how=\"inner\", on=\"id\")\n",
    "topSubmissionsNonOver18JoinedComments = filteredSubmissionsNonOver18JoinedComments.sort_values(by=\"counts\", ascending=False)[:10]\n",
    "print(topSubmissionsNonOver18JoinedComments)\n",
    "topSubmissionsNonOver18JoinedComments.to_csv(\"top_submission_non_over_18.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelovanje podataka grafovima\n",
    "Skup podataka modelujemo pomoću 4 različita grafa:\n",
    "1. SNet (Subreddit network) - sadrži kompletne podatke, sve sabredite i interakcije sa njima\n",
    "2. SNetF (Subreddit network filtered) - filtrirani SNet na osnovu broja korisnika koji definišu interakciju izmedju više sabredita\n",
    "3. SNetT (Subreddit network targeted) - filtrirani SNet na osnovu odabranih sabredita i grana kojima su povezani\n",
    "4. UserNet - sadrži interakcije između korisnika - komentare na objave ili na komentare\n",
    "\n",
    "Iz SNet eliminišemo sve čvorove koji nemaju nijednu granu kako bismo omogućili dalju analizu povezanosti čvorova grafa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "snet = nx.Graph()\n",
    "snet.add_nodes_from(allSubredditIds)\n",
    "\n",
    "authorSubredditIdGroups = allData.groupby([\"author\", \"subreddit_id\"]).groups\n",
    "groups = dict()\n",
    "for author, subredditId in authorSubredditIdGroups:\n",
    "    if author not in groups:\n",
    "        groups[author] = [subredditId]\n",
    "    else:\n",
    "        groups[author].append(subredditId)\n",
    "\n",
    "for key in groups:\n",
    "    subreddit_ids = groups[key]\n",
    "    for i in range(0, len(subreddit_ids)):\n",
    "        for j in range(i + 1, len(subreddit_ids)):\n",
    "            if snet.has_edge(subreddit_ids[i], subreddit_ids[j]):\n",
    "                snet.edges[subreddit_ids[i], subreddit_ids[j]]['weight'] += 1\n",
    "            else:\n",
    "                snet.add_edge(subreddit_ids[i], subreddit_ids[j], weight=1)\n",
    "\n",
    "snet.remove_nodes_from(list(nx.isolates(snet)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Odabir praga za filtriranje grana po težini\n",
    "Prag za filtriranje je uzet kao prosečna vrednost svih težina grana u grafu SNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_weight = sum([tags[\"weight\"] for u, v, tags in snet.edges(data=True)]) / len(snet.edges)\n",
    "w_threshold = average_weight\n",
    "\n",
    "# TODO: check if commented out works\n",
    "# snetf = snet.edge_subgraph([(u, v) for u, v, tags in snet.edges(data=True) if tags[\"weight\"] > w_threshold])\n",
    "\n",
    "snetf = nx.Graph()\n",
    "snetf.add_nodes_from(allSubredditIds)\n",
    "snetf.add_edges_from([(u, v, tags) for u, v, tags in snet.edges(data=True) if tags[\"weight\"] > w_threshold])\n",
    "\n",
    "snetf.remove_nodes_from(list(nx.isolates(snetf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Odabir sabredita od interesa\n",
    "Sabrediti od interesa za analizu pomoću SNetT su uzeti iz teksta projektog zadatka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetSubreddits = {\n",
    "    \"reddit.com\",\n",
    "    \"pics\",\n",
    "    \"worldnews\",\n",
    "    \"programming\",\n",
    "    \"business\",\n",
    "    \"politics\",\n",
    "    \"obama\",\n",
    "    \"science\",\n",
    "    \"technology\",\n",
    "    \"WTF\",\n",
    "    \"AskReddit\",\n",
    "    \"netsec\",\n",
    "    \"philosophy\",\n",
    "    \"videos\",\n",
    "    \"offbeat\",\n",
    "    \"funny\",\n",
    "    \"entertainment\",\n",
    "    \"linux\",\n",
    "    \"geek\",\n",
    "    \"gaming\",\n",
    "    \"comics\",\n",
    "    \"gadgets\",\n",
    "    \"nsfw\",\n",
    "    \"news\",\n",
    "    \"environment\",\n",
    "    \"atheism\",\n",
    "    \"canada\",\n",
    "    \"math\",\n",
    "    \"Economics\",\n",
    "    \"scifi\",\n",
    "    \"bestof\",\n",
    "    \"cogsci\",\n",
    "    \"joel\",\n",
    "    \"Health\",\n",
    "    \"guns\",\n",
    "    \"photography\",\n",
    "    \"software\",\n",
    "    \"history\",\n",
    "    \"ideas\",\n",
    "}\n",
    "\n",
    "targetSubredditIds = [allData[allData[\"subreddit\"] == targetSubreddit][\"subreddit_id\"].unique()[0] for targetSubreddit in targetSubreddits]\n",
    "snett = snet.subgraph(targetSubredditIds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UserNet\n",
    "Modelujemo interakcije korisnika društvene mreže usmerenim grafom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authorComments = pd.concat([filteredComments[\"author\"], filteredComments[\"link_id\"].map(lambda element: element.split(\"_\")[1])], axis=1).rename(columns={\"link_id\": \"id\"})\n",
    "authorToAuthorInteractions = groupby_count(authorComments.merge(allData[[\"author\", \"id\"]], on=\"id\", how=\"inner\", suffixes=[\"_from\", \"_to\"]), [\"author_from\", \"author_to\"])\n",
    "edge_list = authorToAuthorInteractions.rename(columns={\"author_from\": \"source\", \"author_to\": \"target\", \"counts\": \"weight\"})\n",
    "usernet = nx.from_pandas_edgelist(edge_list, edge_attr=True, create_using=nx.DiGraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dobijene grafove čuvamo u standardnom `gml` formatu na disku kako bismo im mogli pristupati i iz eksternih alata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gml(snet, \"snet.gml\")\n",
    "nx.write_gml(snetf, \"snetf.gml\")\n",
    "nx.write_gml(snett, \"snett.gml\")\n",
    "nx.write_gml(usernet, \"usernet.gml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generisanje Erdos-Renyi mreža\n",
    "Erdos-Renyi mreže koristimo za poređenje sa mrežama reddit podataka.\n",
    "\n",
    "Verovatnoća za stvaranje grana u grafu je odabrana kao gustina grafova koje ispitujemo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erdos_renyi_snet = nx.erdos_renyi_graph(n=snet.number_of_nodes(), p=nx.density(snet))\n",
    "erdos_renyi_snetf = nx.erdos_renyi_graph(n=snetf.number_of_nodes(), p=nx.density(snetf))\n",
    "erdos_renyi_snett = nx.erdos_renyi_graph(n=snett.number_of_nodes(), p=nx.density(snett))\n",
    "erdos_renyi_usernet = nx.erdos_renyi_graph(n=usernet.number_of_nodes(), p=nx.density(usernet), directed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gml(erdos_renyi_snet, \"erdos_renyi_snet.gml\")\n",
    "nx.write_gml(erdos_renyi_snetf, \"erdos_renyi_snetf.gml\")\n",
    "nx.write_gml(erdos_renyi_snett, \"erdos_renyi_snett.gml\")\n",
    "nx.write_gml(erdos_renyi_usernet, \"erdos_renyi_usernet.gml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analiza modelovanih grafova\n",
    "### Klub bogatih\n",
    "Kako bi izvrsavanje funkcija trajalo kratko, koristi se nenormalizovana varijanta.\n",
    "Kao sto se moze videti sa grafika dole, svi grafovi ispoljavaju klub bogatih (cvorovi su u klubu bogatih za vrednosti 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snet_rich_club_coefficient = nx.rich_club_coefficient(snet, normalized=False)\n",
    "snetf_rich_club_coefficient = nx.rich_club_coefficient(snetf, normalized=False)\n",
    "snett_rich_club_coefficient = nx.rich_club_coefficient(snett, normalized=False)\n",
    "usernet_rich_club_coefficient = nx.rich_club_coefficient(usernet, normalized=False)\n",
    "\n",
    "pd.DataFrame.from_dict(snet_rich_club_coefficient, orient=\"index\").plot(title=\"SNet rich club coefficient\", grid=True, legend=False)\n",
    "pd.DataFrame.from_dict(snetf_rich_club_coefficient, orient=\"index\").plot(title=\"SNetF rich club coefficient\", grid=True, legend=False)\n",
    "pd.DataFrame.from_dict(snett_rich_club_coefficient, orient=\"index\").plot(title=\"SNetT rich club coefficient\", grid=True, legend=False)\n",
    "pd.DataFrame.from_dict(usernet_rich_club_coefficient, orient=\"index\").plot(title=\"UserNet rich club coefficient\", grid=True, legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asortativna analiza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Bogdan\\Desktop\\asm\\asm-reddit-analysis\\reddit-analysis.ipynb Cell 28\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Bogdan/Desktop/asm/asm-reddit-analysis/reddit-analysis.ipynb#X46sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(nx\u001b[39m.\u001b[39;49massortativity(snetf))\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "// TODO: implement"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9bd2768395b42109e73d907534bd94663cdcd054d84cf8c7fc88edcbed46f4a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
